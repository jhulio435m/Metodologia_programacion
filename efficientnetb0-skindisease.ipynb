{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import Library"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T22:43:05.707897Z","iopub.status.busy":"2024-06-07T22:43:05.707035Z","iopub.status.idle":"2024-06-07T22:43:05.715289Z","shell.execute_reply":"2024-06-07T22:43:05.71438Z","shell.execute_reply.started":"2024-06-07T22:43:05.707861Z"},"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import random\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.applications.efficientnet import preprocess_input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n","from tensorflow import keras\n","from tensorflow.keras.applications import MobileNet,EfficientNetB0, InceptionV3,ResNet50\n","from tensorflow.keras.layers import GlobalMaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score,recall_score, f1_score\n"]},{"cell_type":"markdown","metadata":{},"source":["# Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T22:33:34.214584Z","iopub.status.busy":"2024-06-07T22:33:34.214191Z","iopub.status.idle":"2024-06-07T22:33:53.230253Z","shell.execute_reply":"2024-06-07T22:33:53.229331Z","shell.execute_reply.started":"2024-06-07T22:33:34.214556Z"},"trusted":true},"outputs":[],"source":["train_val_path = '/kaggle/input/skin-disease-dataset/skin-disease-datasaet/train_set'\n","test_path = '/kaggle/input/skin-disease-dataset/skin-disease-datasaet/test_set'\n","\n","datagen = ImageDataGenerator(\n","    rotation_range=30,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    shear_range=0.1,\n","    zoom_range=0.1,\n","    horizontal_flip=True,\n","    brightness_range=[0.8, 1.2],\n","    fill_mode='reflect'\n",")\n","\n","train_data = []\n","val_data = []\n","\n","train_class_counts = {}\n","val_class_counts ={}\n","\n","for folder in sorted(os.listdir(train_val_path)):\n","    folder_path = os.path.join(train_val_path, folder)\n","    file = os.listdir(folder_path)\n","    num_train = int(0.8 * len(file))\n","    files_train = random.sample(file, num_train)\n","    files_val = list(set(file) - set(files_train))\n","    \n","    train_class_counts[folder] = 0\n","    val_class_counts[folder] = 0\n","    \n","    for file in files_train:\n","        file_path = os.path.join(folder_path, file)\n","        img = cv2.imread(file_path)\n","        img = cv2.resize(img, (224, 224)) \n","        train_data.append((img, folder))\n","\n","        img_array = np.expand_dims(img, axis=0)\n","\n","        for _ in range(2):\n","            augmented_img = datagen.flow(img_array).next()[0].astype(np.uint8)\n","            train_data.append((augmented_img, folder))\n","        \n","        train_class_counts[folder] += 3  \n","\n","    for file in files_val:\n","        file_path = os.path.join(folder_path, file)\n","        img = cv2.imread(file_path)\n","        img = cv2.resize(img, (224, 224))\n","        val_data.append((img, folder))\n","        \n","        val_class_counts[folder] += 1 \n","\n","test_data = []\n","test_class_counts = {}\n","\n","for folder in sorted(os.listdir(test_path)):\n","    folder_path = os.path.join(test_path, folder)\n","    files_test = os.listdir(folder_path)\n","    test_class_counts[folder] = 0\n","    for file in files_test:\n","        file_path = os.path.join(folder_path, file)\n","        img = cv2.imread(file_path)\n","        img = cv2.resize(img, (224, 224)) \n","        test_data.append((img, folder))\n","        img_array = np.expand_dims(img, axis=0)\n","        test_class_counts[folder] += 1  \n","    \n","for class_name, count in train_class_counts.items():\n","    print(f\"Kelas '{class_name}' dalam data TRAIN {count} gambar.\")\n","\n","for class_name, count in val_class_counts.items():\n","    print(f\"Kelas '{class_name}' dalam data VALIDASI {count} gambar.\")\n","    \n","for class_name, count in test_class_counts.items():\n","    print(f\"Kelas '{class_name}' dalam data TEST {count} gambar.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T22:33:53.233189Z","iopub.status.busy":"2024-06-07T22:33:53.232562Z","iopub.status.idle":"2024-06-07T22:33:54.368774Z","shell.execute_reply":"2024-06-07T22:33:54.367876Z","shell.execute_reply.started":"2024-06-07T22:33:53.233149Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","class_images = {}\n","\n","for img, label in train_data:\n","    if label not in class_images:\n","        class_images[label] = img\n","\n","fig, axes = plt.subplots(2, 4, figsize=(10, 5))\n","plt.suptitle('LABELS OF EACH IMAGE')\n","\n","for (label, img), ax in zip(class_images.items(), axes.flatten()):\n","    ax.xaxis.set_ticklabels([])\n","    ax.yaxis.set_ticklabels([])\n","    ax.grid(True)\n","    ax.set_title(label)\n","    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Perancangan Model "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T22:34:47.671536Z","iopub.status.busy":"2024-06-07T22:34:47.671129Z","iopub.status.idle":"2024-06-07T22:34:50.503962Z","shell.execute_reply":"2024-06-07T22:34:50.502868Z","shell.execute_reply.started":"2024-06-07T22:34:47.671489Z"},"trusted":true},"outputs":[],"source":["tf.keras.backend.clear_session()\n","\n","base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","base_model.trainable = False\n","\n","num_classes = 8\n","x = GlobalMaxPooling2D()(base_model.output)\n","\n","x = Dense(512, activation='relu', kernel_initializer='he_normal')(x)\n","x = BatchNormalization()(x)\n","x = Dropout(0.5)(x)\n","   \n","predictions = Dense(num_classes, activation='softmax')(x)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T22:34:50.506353Z","iopub.status.busy":"2024-06-07T22:34:50.506001Z","iopub.status.idle":"2024-06-07T22:34:51.141653Z","shell.execute_reply":"2024-06-07T22:34:51.140685Z","shell.execute_reply.started":"2024-06-07T22:34:50.506325Z"},"trusted":true},"outputs":[],"source":["model = Model(inputs=base_model.input, outputs=predictions)\n","model.compile(optimizer='adamax', loss='categorical_crossentropy', metrics=['accuracy'])\n","print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T22:34:51.14323Z","iopub.status.busy":"2024-06-07T22:34:51.142905Z","iopub.status.idle":"2024-06-07T22:34:51.632008Z","shell.execute_reply":"2024-06-07T22:34:51.630986Z","shell.execute_reply.started":"2024-06-07T22:34:51.143181Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import to_categorical\n","\n","X_train, y_train = zip(*train_data)\n","X_val, y_val = zip(*val_data)\n","\n","X_train = preprocess_input(np.array(X_train))\n","X_val = preprocess_input(np.array(X_val))\n","\n","le = LabelEncoder()\n","y_train_encoded = le.fit_transform(y_train)\n","y_val_encoded = le.transform(y_val)\n","\n","y_train_one_hot = to_categorical(y_train_encoded, num_classes)\n","y_val_one_hot = to_categorical(y_val_encoded, num_classes)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Training Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T22:34:51.633569Z","iopub.status.busy":"2024-06-07T22:34:51.633274Z","iopub.status.idle":"2024-06-07T22:38:41.997287Z","shell.execute_reply":"2024-06-07T22:38:41.996276Z","shell.execute_reply.started":"2024-06-07T22:34:51.633542Z"},"trusted":true},"outputs":[],"source":["EPOCHS = 100\n","BATCH_SIZE = 128\n","\n","best_model_dir = '/kaggle/working/'\n","early_stopping = EarlyStopping(monitor='val_loss', patience=15)\n","model_checkpoint = ModelCheckpoint(\n","    os.path.join(best_model_dir, 'best_model_EfficientNetB0.h5'),\n","    monitor='val_loss', \n","    save_best_only=True,\n","    mode='min', \n","    verbose=1\n",")\n","\n","history = model.fit(X_train, y_train_one_hot,\n","                    validation_data=(X_val, y_val_one_hot),\n","                    epochs=EPOCHS, \n","                    batch_size=BATCH_SIZE,\n","                    callbacks=[early_stopping, model_checkpoint])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T22:38:42.001702Z","iopub.status.busy":"2024-06-07T22:38:42.001303Z","iopub.status.idle":"2024-06-07T22:38:42.272061Z","shell.execute_reply":"2024-06-07T22:38:42.271271Z","shell.execute_reply.started":"2024-06-07T22:38:42.001675Z"},"trusted":true},"outputs":[],"source":["train_loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(1, len(train_loss) + 1)\n","\n","plt.plot(epochs, train_loss,label='Training loss', marker='o')\n","plt.plot(epochs, val_loss,label='Validation loss', marker='o')\n","plt.title('Training and Validation Losses')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T22:38:42.273576Z","iopub.status.busy":"2024-06-07T22:38:42.273239Z","iopub.status.idle":"2024-06-07T22:38:42.623755Z","shell.execute_reply":"2024-06-07T22:38:42.622728Z","shell.execute_reply.started":"2024-06-07T22:38:42.273548Z"},"trusted":true},"outputs":[],"source":["train_loss = history.history['accuracy']\n","val_loss = history.history['val_accuracy']\n","\n","epochs = range(1, len(train_loss) + 1)\n","\n","plt.plot(epochs, train_loss,label='Training accuracy', marker='o')\n","plt.plot(epochs, val_loss,label='Validation accuracy', marker='o')\n","plt.title('Training and Validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Acc')\n","plt.legend()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluasi Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T22:38:42.625816Z","iopub.status.busy":"2024-06-07T22:38:42.625325Z","iopub.status.idle":"2024-06-07T22:38:42.630817Z","shell.execute_reply":"2024-06-07T22:38:42.629769Z","shell.execute_reply.started":"2024-06-07T22:38:42.625777Z"},"trusted":true},"outputs":[],"source":["test_path = '/kaggle/input/skin-disease-dataset/skin-disease-datasaet/test_set'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T22:38:57.211123Z","iopub.status.busy":"2024-06-07T22:38:57.210058Z","iopub.status.idle":"2024-06-07T22:38:59.589821Z","shell.execute_reply":"2024-06-07T22:38:59.588715Z","shell.execute_reply.started":"2024-06-07T22:38:57.211085Z"},"trusted":true},"outputs":[],"source":["model = load_model('/kaggle/working/best_model_EfficientNetB0.h5') "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T22:38:59.592215Z","iopub.status.busy":"2024-06-07T22:38:59.591898Z","iopub.status.idle":"2024-06-07T22:39:20.296723Z","shell.execute_reply":"2024-06-07T22:39:20.295626Z","shell.execute_reply.started":"2024-06-07T22:38:59.592175Z"},"trusted":true},"outputs":[],"source":["real_label = []\n","predicted_class = []\n","\n","for folder in sorted(os.listdir(test_path)):\n","    folder_path = os.path.join(test_path, folder)\n","    for file in os.listdir(folder_path):\n","        file_path = os.path.join(folder_path, file)\n","        img = cv2.imread(file_path)\n","        img = cv2.resize(img, (224,224))\n","        img = preprocess_input(np.array([img]))  \n","\n","        predictions = model.predict(img)\n","        real_label.append(folder)\n","        predicted_class_index = np.argmax(predictions)\n","        predicted_class.append(le.classes_[predicted_class_index])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T22:43:13.994497Z","iopub.status.busy":"2024-06-07T22:43:13.993567Z","iopub.status.idle":"2024-06-07T22:43:14.011746Z","shell.execute_reply":"2024-06-07T22:43:14.010659Z","shell.execute_reply.started":"2024-06-07T22:43:13.994461Z"},"trusted":true},"outputs":[],"source":["real_labels = np.array(real_label)\n","predicted_classes = np.array(predicted_class)\n","\n","accuracy = accuracy_score(real_labels, predicted_classes)\n","precision = precision_score(real_labels, predicted_classes, average='weighted')\n","recall = recall_score(real_labels, predicted_classes, average='weighted')\n","f1 = f1_score(real_labels, predicted_classes, average='weighted')\n","\n","print(f\"\\nAccuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T22:43:14.014799Z","iopub.status.busy":"2024-06-07T22:43:14.013869Z","iopub.status.idle":"2024-06-07T22:43:14.03398Z","shell.execute_reply":"2024-06-07T22:43:14.033124Z","shell.execute_reply.started":"2024-06-07T22:43:14.014771Z"},"trusted":true},"outputs":[],"source":["real_labels = np.array(real_label)\n","predicted_classes = np.array(predicted_class)\n","\n","conf_matrix = confusion_matrix(real_labels, predicted_classes)\n","\n","class_names = [str(i) for i in range(len(conf_matrix))] \n","print(classification_report(real_labels, predicted_classes, target_names=class_names))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T22:43:14.035456Z","iopub.status.busy":"2024-06-07T22:43:14.035105Z","iopub.status.idle":"2024-06-07T22:43:14.460131Z","shell.execute_reply":"2024-06-07T22:43:14.45928Z","shell.execute_reply.started":"2024-06-07T22:43:14.035422Z"},"trusted":true},"outputs":[],"source":["conf_matrix = confusion_matrix(real_label, predicted_class)\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Convert Model ke TFJS"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T22:43:14.462885Z","iopub.status.busy":"2024-06-07T22:43:14.462426Z","iopub.status.idle":"2024-06-07T22:43:21.016583Z","shell.execute_reply":"2024-06-07T22:43:21.015564Z","shell.execute_reply.started":"2024-06-07T22:43:14.46285Z"},"trusted":true},"outputs":[],"source":["!tensorflowjs_converter --input_format keras best_model_EfficientNetB0.h5 tfjs/model"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":3860205,"sourceId":6695743,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
